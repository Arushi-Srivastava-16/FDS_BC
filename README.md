# Breast Cancer Detection with Explainable AI and Multi-View Learning

---

## ğŸ§¬ Overview

This repository presents a modular and explainable deep learning framework for **early-stage breast cancer detection** using **paired-view mammograms**. The model leverages **self-supervised learning (SimCLR)**, **prototype-based interpretability (ProtoPNet)**, and **ROI-guided cropping (FocalNet-DINO)** to create a transparent diagnostic pipeline. This system is designed to support radiologists with interpretable, high-accuracy cancer predictions while retaining clinical trust.

---

## ğŸ¯ Motivation

Breast cancer remains a leading cause of mortality among women worldwide. While deep learning models have demonstrated promise, they often suffer from:

* âŒ Lack of explainability
* âŒ Dependence on large labeled datasets
* âŒ Poor cross-population generalization
* âŒ Underutilization of paired CC/MLO views

We address these gaps with a pipeline that combines **SimCLR**, **ProtoPNet**, and **Grad-CAM**, validated on a **balanced, diverse mammogram dataset**.

---

## ğŸ§  Methodology

### ğŸ”¹ 1. **ROI Detection with FocalNet-DINO**

* Used to locate tumor regions using bounding box annotations
* Output: Region-specific 224Ã—224 image crops

### ğŸ”¹ 2. **Self-Supervised Contrastive Learning (SimCLR)**

* Paired mammogram (CC/MLO) crops passed to ResNet50 backbone
* Contrastive learning to align multi-view features
* Encoder saved for downstream classification

### ğŸ”¹ 3. **Multi-View Classification (MLP)**

* CC and MLO embeddings concatenated
* Trained on a binary cross-entropy loss (malignant vs benign)

### ğŸ”¹ 4. **Explainable AI (ProtoPNet + Grad-CAM)**

* ProtoPNet uses learned prototypes to compare against test patches
* Grad-CAM overlays model attention for individual predictions
* Final output includes most activated prototypes and heatmaps

### ğŸ”¹ 5. **Bayesian Uncertainty Estimation (Optional)**

* Monte Carlo Dropout for confidence scoring

---

## ğŸ“Š Final Results

| Metric                 | Value      |
| ---------------------- | ---------- |
| **Accuracy**           | **84.32%** |
| **Precision**          | **67.76%** |
| **Recall**             | **86.25%** |
| **F1-score**           | **75.89%** |
| **AUC-ROC**            | **0.9148** |
| **Avg Precision (PR)** | **0.8557** |

> Achieved state-of-the-art balance of interpretability and accuracy.

---

## ğŸ“ Repository Structure

```
breast_cancer_detection/
â”œâ”€â”€ models/                         # SimCLR, ProtoPNet, MLP, etc.
â”œâ”€â”€ data/                           # Paired crops with metadata
â”œâ”€â”€ detect_from_pair.py            # CC/MLO pair detection + cropping
â”œâ”€â”€ train_simclr.py                # Train SimCLR encoder
â”œâ”€â”€ train_classifier.py            # Multi-view classifier (MLP)
â”œâ”€â”€ train_protopnet.py             # Train ProtoPNet on SimCLR features
â”œâ”€â”€ gradcam.py                     # Grad-CAM heatmap generator
â”œâ”€â”€ generate_protopnet_figures.py # Visualizations for ProtoPNet (Figs 3-5)
â”œâ”€â”€ evaluation.py                  # Precision, Recall, AUC, Confusion Matrix
â””â”€â”€ README.md                      # This file
```

---

## ğŸ–¼ï¸ Visual Outputs

### ğŸ”¹ Patch-Level Predictions (Fig. 3)

> Generated using ProtoPNet + patch similarity + class confidence

### ğŸ”¹ Most Activated Prototypes (Fig. 4)

> Shows nearest learned prototypes from positive and negative classes

### ğŸ”¹ Prototype Activation Heatmap (Fig. 5)

> Patch-wise similarity to each prototype

---

## ğŸš€ How to Run

```bash
# Step 1: Pretrain SimCLR
python train_simclr.py

# Step 2: Train Multi-view MLP Classifier
python train_classifier.py

# Step 3: Train ProtoPNet with frozen encoder
python train_protopnet.py

# Step 4: Run full pipeline
python detect_from_pair.py --input_dir test_pair/

# Step 5: Visual Explanation (GradCAM)
python gradcam.py

# Step 6: Generate Publication-Quality Figures
python generate_protopnet_figures.py --input_dir final_test/
```

---

## âœ¨ Key Contributions

* ğŸ“Œ Multi-view patch learning using paired CC/MLO views
* ğŸ” SimCLR contrastive encoder with no labels
* ğŸ§  ProtoPNet-based transparent patch classification
* ğŸŒ¡ï¸ GradCAM for human-readable attention overlays
* ğŸ” Bayesian dropout for uncertainty estimation
* ğŸ“Š Balanced and synthetic augmentation strategies for generalization

---

## ğŸ“¦ Dependencies

Install all required packages:

```bash
pip install -r requirements.txt
```

Major dependencies:

* PyTorch, TorchVision
* sklearn, matplotlib, seaborn
* pandas, PIL, tqdm

---

## ğŸ‘©â€âš•ï¸ Authors

* **Arushi Srivastava** â€“ 2022A7PS0188U (BITS Pilani, Dubai)
* **Nikhil Sharma** â€“ 2022A7PS0337U (BITS Pilani, Dubai)

---

## ğŸ™Œ Acknowledgements

We would like to thank:

* Our mentor **Dr. Pranav** for continuous guidance and support
* The **VINDR Mammogram Dataset team** for making high-quality data available
* The **ProtoPNet authors** for the interpretability framework inspiration
* All contributors of **PyTorch**, **Scikit-learn**, and **TorchVision** libraries

---

## ğŸ“„ Citation

```
Arushi Srivastava, Nikhil Sharma,
"Advancing Breast Cancer Detection with Explainable AI and Multi-View Learning",
BITS Pilani Dubai Campus, 2025.
```
